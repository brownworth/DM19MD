{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we're going to use the read excel functionality of Pandas. The `sheet_name=None` means that we want to include all the sheets in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkm_data = pd.read_excel('./KA_TKM_2019-08-10.xlsx',sheet_name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you take the type of the variable, you find something different than usual, but it's not completely foreign to us. Look at the last part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tkm_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read_excel returned a type of a dictionary. We know what dictionaries have: keys and values. Let's look at the keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkm_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since these keys are attached to values, I wonder what `type()` we see if we use the `.get(key)` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tkm_data.get('KA-Tags'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that this new object is a _dictionary_ of _dataframes_ ! Since all of the values are dataframes, we can do dataframe stuff with them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkm_data.get('KA-Tags').info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ease of typing, let's just create a new variable and point it at the dataframe in the dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ka_tags = tkm_data.get('KA-Tags')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start looking at what the database contains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ka_tags.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'Key Activity' field has some codes paired with descriptions. I wonder if those pairs are always consistent. First, let's look at how many unique values are in that field. We're going to use the `.unique()` to return a numpy array of values and then look at the size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ka_tags['Key Activity'].unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to introduce some other ways to think about numpy arrays, they can themselves be passed as arguments to a function. This is a numpy function that counts the non-zero values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.count_nonzero(ka_tags['Key Activity'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to investigate the codes and the descriptions separate from each other. Let's see if we can see what an example might be: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ka_tags.loc[225,'Key Activity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this, it seems that the code at the front is separated from the description at the end with a space-hyphen-space composite delimiter. I wonder if we could _split_ using that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ka_tags['Key Activity'].str.split(' - ').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split on multiple consecutive characters seems to work without an error. We've now created a bunch of lists. We can use the apply method to convert these lists to series in place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ka_tags['Key Activity'].str.split(' - ').apply(pd.Series).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That third column is a little weird. It probably means that there is an additional space-hyphen-space in the text on a few of these. No problem! Let's just split on the first occurrence, by passing an additional argument to the `.split()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ka_tags['Key Activity'].str.split(' - ',1).apply(pd.Series).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks better. Codes in column 0, descriptions in column 1 (hopefully). But is this the best way to do this? There are a couple of ways to convert lists into when splitting on a character. How do we determine the best one? Thankfully, Python has the 'timeit' command. Using it, we can run a segment of code numerous times, and see how time efficent it is. We can do the same thing with another code segment and compare the two. Check this out: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit ka_tags['Key Activity'].str.split(' - ',1).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The split method in Pandas can take an additional argument: `expand`. This will take the results of the split operation (one or more lists) and convert them to series in place. If we use `%timeit` again, we can see if it is better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit ka_tags['Key Activity'].str.split(' - ',1,expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wow! That is a reduction of upwards of 90%! In this particular case, we don't see much of a difference, as the dataset is relatively small. However, if you're trying to do transformations on significantly larger datasets, a reduction of this size would be tremendous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's make sure that the operations are equivalent, just to be sure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all((ka_tags['Key Activity'].str.split(' - ',1).apply(pd.Series)) == (ka_tags['Key Activity'].str.split(' - ',1,expand=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving forward, let's use the more efficient method and check on our results. To start, we'll see how many unique codes there are. Since we're creating a DataFrame, we can use our indexers to separate the columns. Afterward, we'll use `.unique().size` to count the number of unique values in this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ka_tags['Key Activity'].str.split(' - ',1,expand=True).iloc[:,0].unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a different number from above. I wonder how many unique descriptions there are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ka_tags['Key Activity'].str.split(' - ',1,expand=True).iloc[:,1].unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe there are supposed to be codes that are different from the associated descriptions. In case there aren't, though, let's `.groupby()` the two columns and count them, ordered by code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ka_tags['Key Activity'].str.split(' - ',1,expand=True).groupby([0,1]).size().reset_index(name='Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can already see pairs that don't go with their codes. What if we reverse the order, and sort by description?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ka_tags['Key Activity'].str.split(' - ',1,expand=True).groupby([1,0]).size().reset_index(name='Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordering the data in this way shows a couple of situations where missing words or descriptions might be read by a human as similar, but would be considered very different by a computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ka_tags['Key Activity'].str.split(' - ',1,expand=True).groupby([1,0]).size().reset_index(name='Count').iloc[222,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ka_tags['Key Activity'].str.split(' - ',1,expand=True).groupby([1,0]).size().reset_index(name='Count').iloc[223,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ka_tags['Key Activity'].str.split(' - ',1,expand=True).groupby([1,0]).size().reset_index(name='Count').iloc[224,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ka_tags['Key Activity'].str.split(' - ',1,expand=True).groupby([1,0]).size().reset_index(name='Count').iloc[225,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ka_tags['Key Activity'].str.split(' - ',1,expand=True).groupby([1,0]).size().reset_index(name='Count').iloc[18,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ka_tags['Key Activity'].str.split(' - ',1,expand=True).groupby([1,0]).size().reset_index(name='Count').iloc[19,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a new DataFrame with our split text, and concatenate it on the existing DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ka_tags = pd.concat([ka_tags,ka_tags['Key Activity'].str.split(' - ',1,expand=True)],axis=1).rename(columns={0:'code',1:'name'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we're aware that there are some inconsistencies in these fields, let's work on cleaning them up. We'll start by eliminating one of the biggest traps in messy data - the repeated whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ka_tags['name'].unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ka_tags['name'].str.replace('\\s{2,}',' ').unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok. So that isn't really that impressive of change. But, remember, to a computer, `tuna fish` and `tuna  fish` are different strings. Hey, it's a start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ka_tags['name'] = ka_tags['name'].str.replace('\\s+',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz, process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ka_tags[ka_tags['name'].str.contains('high-quality')]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ka_tags.loc[931,'name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process.extract(ka_tags.loc[931,'name'],ka_tags['name'].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
